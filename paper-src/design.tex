\section{Design}
\label{sec:design}
We next present the detailed design of \project{} based on addressing the aforementioned three design challenges ($\S$\ref{subsect:design-challenges}).

\subsection{Heterogeneous Confidential Computing Framework}
\label{subsec:design-sef}

To address challenge \#1, we present the design of a heterogeneous confidential computing framework that allows to securely process SQL queries across the host and storage. Figure~\ref{fig:design-hetero-tee} presents its components. It consists of a distributed execution runtime that enables secure data processing queries to run across heterogeneous TEE technologies -- Intel SGX or ARM TrustZone. % -- while preserving the confidentiality, integrity, and freshness of data and computations. 
The runtime provides a unified interface to an application that intends to take advantage of the \csd for performance speedups. Next, we present the core security mechanisms of our framework intended to protect in-memory query execution and persistent data on untrusted storage medium. %to extend trust from in-memory computing to secure the persistent data on untrusted storage medium.

\myparagraph{Protection for in-memory query execution} In the host, which we assume to be an x86 server, the host engine runs inside a memory-protected domain implemented by a single SGX enclave. Together with two auxiliary components---the query engine and the query partitioner---it is responsible for handling, partitioning, and dispatching query requests. These components execute within an enclave, untrusted parties cannot inspect their memory or tamper with critical data and operations (e.g., query partitioning). %Thus, integrity and confidentiality of these operations, and of the data they operate on is guaranteed.

In contrast to the host, the storage system is based on ARM architecture where the only available TEE-enabling technology is TrustZone (ARM v9 Realms~\cite{arm-cca} is not released yet). With a TrustZone-based TEE, a strawman approach for securing the storage engine would be to implement as a trusted application (TA) and run it inside the secure world. However, to enable split queries to access persistent data on the storage medium, the storage engine requires full-blown OS support with all the necessary device drivers and file systems. Typically, no such support is available in the secure world given that the trusted OS responsible for managing TAs is bare minimal.

To overcome this problem, we adopt an architecture spanning across both worlds. The secure world only runs certain security-critical functions, including generation of remote attestation quotes, secure storage primitives, and securely bootstrapping the system. These functions are implemented as trusted applications (see Figure~\ref{fig:design-hetero-tee}). The normal world houses a supporting OS stack along with the storage engine's query engine and secure storage system. To propagate trust from the secure world to the normal world, at boot time, the trusted OS performs a hash-based integrity measurement of the normal world software and hands over the control to the normal world OS. Unless the hashes reflect \project's trusted software stack for the normal world the trusted monitor will consider the storage system unsafe and thus ineligible for handling query offloading requests.

Thus, the storage engine is protected by two mechanisms: i) the storage system's TAs are protected by the secure world's trusted OS, and ii) the storage system's components that run in the normal world are supervised by a trusted OS stack. The firmware is trusted to provide isolation between offloaded queries, and prevent them from tampering with each other's code and data. Hence, we can guarantee the confidentiality and integrity of offloaded queries and processed data.

\myparagraph{Protection for on-storage data} To guarantee the confidentiality, integrity, and freshness of data in the untrusted storage medium, \project{} relies on several components in the secure storage system (see 
Figure~\ref{fig:design-hetero-tee}). Some components live in the normal world, with the secure storage TA running in the secure world. It allows the query engine to read or write units of data (fixed at \SI{4}{\kibi\byte}) stored on untrusted medium. Data read or write operations can only be authorized (and thus executed) as long as the trusted monitor has i) vouched for the authenticity of the storage system, and ii) verified the compliance of this setup with the security policy originally provisioned through the client.

The secure storage framework stores persistent state on both untrusted medium (e.g., SSD) and RPMB-backed trusted medium. On an untrusted medium, it reserves a data region for storing the (encrypted) data units sequentially and a meta-data region that preserves a streamlined Merkle tree for integrity protection. For simplicity, \project uses a single secret (symmetric) key to encrypt all the data units, but other management schemes can be adopted (e.g., one key per unit). The secure storage TA generates this key during the system initialization and shares it only with a trusted implementation of \project's storage system running in normal world. To survive system reboots, the encryption key is stored in RPMB memory. For integrity protection, \project %uses a key deterministically derived from the data encryption key to 
generates an HMAC for each data unit. It then recursively builds a Merkle tree also employing HMACs to create the internal nodes and root of the tree. This tree ensures that the data units cannot be silently displaced or suppressed by an adversary with physical access to the untrusted medium.

To prevent rollback attacks and ensure that the Merkle tree itself is fresh, we need to only ensure that the root of the tree is fresh. To this end, we rely on the secure storage TA and on the RPMB region present in an eMMC. First, the storage TA generates a new key derived from a unique, device-specific hardware key, which bounds the data to the CPU. The storage TA uses the new key to generate a HMAC of the Merkle tree root and writes down this HMAC to the RPMB. Freshness is preserved by verifying that the HMAC of the root of the Merkel tree matches the version stored on RPMB. %Whenever \project{} loads the Merkel tree from untrusted medium and needs to verify the freshness of the tree's root value (once at startup), it sends a request to the secure storage TA to compare if this value is equal to the tree root value stored in the RPMB region. 

\subsection{Policy Compliance Monitor}
\label{subsec:design-trusted-monitor}



To address challenge \#2, we present the design of a policy compliance infrastructure that enforces security policies in dynamic, heterogeneous cloud environments. The central component of this infrastructure is the trusted monitor, which abstracts away the process of remote attestation of host and storage nodes by acting as their root of trust. Clients are only required to directly trust the monitor, and submit queries and associated execution and data policies.

The trusted monitor service runs inside an SGX enclave, either on the host or on a dedicated server (see Figure~\ref{fig:design-hetero-tee}). To be able to enforce client policies, the first essential step is to obtain hard proof about the configuration of the host and storage system nodes. This proof must ascertain the authenticity and integrity of the software implementing the host engine and in the storage engine. Along with the trusted monitor software they (host engine and storage engine) form \project{}'s TCB and therefore they cannot be tampered with. To obtain such a proof, the trusted monitor runs independent remote attestation protocols with host and storage nodes.

\input{figures/design-attestation}

\myparagraph{Attestation of the host} Figure~\ref{fig:design-trusted-monitor}.a describes the steps during which the trusted monitor remotely attests the integrity and authenticity of the software running in the host engine enclave. After establishing a secure channel over TLS (step 1), the trusted monitor issues a quote request to the host (step 2), who replies with a quote response (step 3). Then, by checking the quote signature, the trusted monitor decides whether the configuration of the host is trustworthy. If so, it generates a public key pair where the public key is certified by the trusted monitor, and sends this information to the host over the secure channel (step 4). The public key certificate will be used by the host to prove to the client that the host has been remotely attested. If the quote verification fails, then the operation is aborted and the host is not authorized to serve \project client requests.

\myparagraph{Attestation of the storage system} %The remote attestation of a storage system node 
This operation involves the interaction between the trusted monitor and the attestation TA running in secure world (see Figure~\ref{fig:design-hetero-tee}). As mentioned in $\S$~\ref{subsec:design-sef}, we rely on a secure boot process to check the storage engine software.
%to ensure that the storage engine software has not been tampered with, we rely on the secure boot process operated by the secure world firmware. 
The root of trust for this process is a device-specific, unique key called the \textit{root of trust public key} (ROTPK), and the initial boot firmware is present in tamper proof ROM. This mechanism ensures that only integrity-protected firmware, signed by trusted parties, will run. The attestation TA leverages this mechanism during the remote attestation protocol. Figure~\ref{fig:design-trusted-monitor}.b describes the steps of this protocol.
The trusted monitor in step (1) requests the certificates from the storage node and challenges the node to prove its authenticity. In step (2) the TA obtains the measurement of the software running in normal world, and step (3) generates a response to the challenge by signing the challenge with a unique key, derived from the ROTPK. %device specific hardware key (i.e., the ROTPK).
In step (4) the TA sends the challenge response, the normal world firmware hash, and the certificate chain generated during secure boot of the storage node. The trusted monitor then verifies the response to the challenge to determine the authenticity of the storage system. The certificate chain is also verified, and on success, the storage node configuration is derived from the certificate chain. Both the configuration data and the certificate chain are used for policy enforcement as explained next. 


\myparagraph{Policy-compliant query partitioning} To execute a query while complying with a user-defined security policy, the client first connects to and attests the host. Once authenticated (by presenting a TLS certificate), a mutually encrypted channel is created to exchange data and commands between the actor and \project{}. The host then submits the query and associated execution policy to the trusted monitor service as shown in Figure~\ref{fig:policy-compl-infra}. The policy compliance infrastructure from Figure~\ref{fig:policy-compl-infra} shows the host engine working in collaboration with the trusted monitor to ensure policy compliant query processing. The host forwards the query and identity of the connecting client to the monitor, which then checks which of the host and storage nodes comply with the execution policy. The trusted monitor then checks if the connected actor has permissions to read and write data by executing queries. If successful, it sends the list of compliant storage nodes to a compliant host node, along with a session key that allows the host to connect securely to the storage node and process the query as explained in the sections above. The trusted monitor rewrites the client query to be policy compliant based on the results of the policy checks. The host decides whether the query is processed across both the host and storage nodes, or only on the host node or not processed at all. For the first case, it needs to partition the query into portions that run on the host and storage nodes respectively, as shown in Figure~\ref{fig:policy-compl-infra}. If none of the storage nodes comply with the client's execution policy then the entire query may be processed on the host node itself. Once the client request has been completed, the monitor initiates a session cleanup protocol. This deletes any sensitive information that is generated during query processing on the host and storage node, such as temporary tables that are generated by the query engine.

\input{figures/policy-compliance-infra-workflow}

\myparagraph{Key management} Once the trusted monitor verifies the authenticity of the hardware and software running on the host and storage nodes, it provides key management services to the nodes. Specifically, it manages and distributes the session keys between the host and storage nodes that is used to create a secure channel for exchanging queries and data between them. After query processing, the trusted monitor revokes the session key and initiates the session cleanup.

\myparagraph{Proofs of integrity and authenticity} To provide per query proofs of integrity and authenticity to the client, the trusted monitor signs the execution environment requirements, as specified in the client's execution policy, using its private key provided all nodes in the setup used for query execution satisfy the requirements. 
%This signature is sent to the client along with the results of the query's execution. 
%The client verifies the signed response with a known set of public keys that represent the authenticity of the trusted monitor.
The client verifies the signed response with the public key of the trusted monitor.

\myparagraph{Separation between the host engine and trusted monitor}
The trusted monitor and the host engine run in separate, hardware protected memory regions. The trusted monitor is a separate entity for scalability, performance and architectural independence reasons. 
%Since it is the root of trust in the system, as it performs tasks related to attestation and key management, it has to be protected and separated from the host engine. 
However, in practice, it can be run on the same node as the host engine, but inside a separate enclave. 
We allow the client to connect to the host, instead of the trusted monitor, to differentiate between operations in the control and data paths. The client uses the trusted monitor, indirectly via the host, for control path operations like attestation and policy compliance. It then connects to the host, in the data path, to exchange queries and data. Thereby, we clearly divide the functionality between the host and trusted monitor, and avoid overloading the trusted monitor, thereby ensuring better scalability and performance.

%\paragraph{Access and audit operations:} As described below, \project{} supports three kinds of operations: \textit{read}, \textit{write} and \textit{exec}. Actors use these operations to store their data on \project{}, tie access policies to the stored data, update policies associated with the stored data, and also update stored data. Additionally, they can also run queries that process the stored data provided they have the permission to do so. Policies are created, optionally, during data insertion. They are updated later, using a \emph{updatePolicy} operation that takes a new policy and a second parameter that represents a \emph{strong} or \emph{eventual} enforcement of the new policy. Since data and associated metadata for policy compliance can be replicated and distributed across multiple storage nodes, the metadata to reflect the new policy must be updated everywhere. If a \emph{strong} update is preferred, then the trusted monitor blocks all requests to the data associated with that policy, until all metadata has been updated to reflect the restrictions imposed by the new policy. Otherwise, if \emph{eventual} update is preferred, the trusted monitor does not block any requests to that data. To be able to investigate data usage and policy violations, \project{} allows a regulatory authority, to obtain information on the ways the data was shared, used and processed. Data providers enforce logging of data and allow a regulatory authority to access this log through an \emph{obtainUserLog} operation.


%\subsection{\project{} API and policy language}
\subsection{Declarative Policy Specification Language}
\label{sec:policylanguage}

To address challenge \#3, we present a declarative policy language that can be used to specify data access and execution policies concisely. %Before we describe this language, we introduce the \project{} interface exposed to all actors highlighting how policy management is affected.

\if0
\myparagraph{\project{} interface} \project{} %defines three kinds of actors, namely: data producers, data consumers, and regulatory authorities (see \autoref{fig:secndp-arch_overview}). %Each of these perform different kinds of tasks. Data producers generate data and tie access and usage policies to that data. Data consumers read and process the data in a manner that is allowed by the data producers. Finally, regulatory authorities are responsible for auditing investigating data breaches and violations of policies. 
\project{} actors (see \autoref{fig:secndp-arch_overview}) can invoke operations through the \project{} interface. Next we describe these operations, which allow actors to: (1) establish sessions, (2) submit user data for storage, tie policies to data, update those policies, and (3) obtain information on how data was used and shared.

\begin{enumerate}[wide=0pt]
\item \vspace{3pt} {\em Session operations:}
All actors in the system interact with \project{} in a session. When an actor connects to \project{}, they present a TLS certificate to authenticate themselves. Once authenticated, a mutually encrypted channel is created to exchange data and commands between the actor and \project{}. The trusted monitor uses the public identity key of the connected actor to figure out if it has the right permissions to read and write data by executing queries. Moreover, the connecting actor receives an attestation quote from the trusted monitor to guarantee the integrity and authenticity of the latter.

\item \vspace{3pt} {\em Access operations:}
As described below, \project{} supports three kinds of operations: \textit{read}, \textit{write} and \textit{exec}. Actors use these operations to store their data on \project{}, tie access policies to the stored data, update policies associated with the stored data, and also update stored data. Additionally, they can also run queries that process the stored data provided they have the permission to do so. Policies are created, optionally, during data insertion. They are updated later, using a \emph{updatePolicy} operation that takes a new policy and a second parameter that represents a \emph{strong} or \emph{eventual} enforcement of the new policy. Since data and associated metadata for policy compliance can be replicated and distributed across multiple storage nodes, the metadata to reflect the new policy must be updated everywhere. If a \emph{strong} update is preferred, then the trusted monitor blocks all requests to the data associated with that policy, until all metadata has been updated to reflect the restrictions imposed by the new policy. Otherwise, if \emph{eventual} update is preferred, the trusted monitor does not block any requests to that data.

\item \vspace{3pt} {\em Audit operations:}
To be able to investigate data usage and policy violations, \project{} allows a data owner or an external party, who has been permitted by the data owner, to obtain information on the ways the data owner's data was shared, used and processed. Data owners enforce logging of data and allow an external party to access this log through an \emph{obtainUserLog} operation.
\end{enumerate}

\fi

% \harsha{spin gdpr challenges in context of ndp; add a time component; our work handles the "risk agnostic data processing"; }

\myparagraph{Policy language predicates}
\project{}'s policy language allows a client to concisely specify the execution context associated with the execution of a query in a split manner, across the host and storage. %By specifying the execution context the client indirectly enforces security policies, for example, by enforcing the firmware that is used to run the query in a split manner. Moreover, the data owner can also specify data access policies during data creation using the policy language, which are enforced by the trusted monitor, during an update or deletion of data at a later point in time. %We describe a few use cases that can be supported by our language in section~\ref{sec:use-cases}.
A policy in \project{} is a combination of predicates described in Table~\ref{tab:secndp-language}. A policy evaluates to true, if and only if all the predicates specified in the policy evaluate to true. In \project{} we have two kinds of policies: \emph{data access} and \emph{data execution} policies. Data execution policies are specified by the client when executing queries. They can be any combination of location and firmware predicates. Data access policies are created (or updated) by the client that creates the database and tables in that database. These policies are associated with permissions for reading or writing on the database or its tables. They are of the form \textit{perm~:condition}. The condition is a combination of predicates and evaluates to true only if all predicates evaluate to true. The predicates are joined using either a '|', which evaluates to true if any of the predicates are true, or a '\&', which evaluates to true if and only if both predicates evaluate to true. An example data access policy is shown below in which user A can read and user B can write to the database.
\vspace{-1mm}
\[
\begin{array}{@{}l@{}}
read~:-~sessionKeyIs(K_{\tt A})\\
write~:-~sessionKeyIs(K_{\tt B})\\
exec~:-~fwVersionStorage(latest) \& fwVersionHost(latest)\\
\end{array}
\]

\vspace{-2mm}
More complex policies, that can be used in the real world to adhere to GDPR rules are described below. % Predicates that can be used to compose policies using \project{}'s policy language are shown in table~\ref{tab:secndp-language}. 
The table describes four kinds of predicates that can be used to compose policies. \emph{sessionKeyIs} enables a client to derive policies to restrict access, by reading or writing, to data, only to certain users based on their identity key $K_ x$. The second kind of predicates enable a client to run data processing operations on nodes, host or storage, only if they are located in a region or regions. The client uses the \emph{storageLocIs} predicate to enforce the offloading of queries only to storage nodes located in region $l$. If no nodes satisfy this property then, as described before, the entire query may be run on the host node itself. The client uses the \emph{hostLocIs} predicate to enforce the running of queries only on host nodes that are located in a specific region $l$. Similarly, the client uses the firmware predicates to enforce processing of queries on nodes that are running software greater than or equal to a certain version $v$. The final two predicates enable a client to specify how their data can be used by an external entity and record all operations that are performed by that entity.

\input{tab_language}



\input{policy_use_cases}

