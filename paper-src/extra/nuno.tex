\if 0
\nuno{I'm a little confused by Figure 2. It's not entirely clear to me who's who. And I also believe that the entity responsible for running our storage system is the data processor, not the data controller. The data controller would be the entity that collects and processes the data in order to provide some given service, e.g., a social network provider. With this in mind, the data consumer represented in this figure would be the data controller, e.g., Facebook. The data owner would be Facebook's end-user. But this raises other questions, such as usability: no Facebook user would specify our kinds of policies. Alternatively, we could think of a B2B scenario, e.g., Facebook is the data owner in the figure, and the data consumer is an ad provider. Facebook tells who can read/write the data, then the ad provider submits queries that must also be validated against the read/write policies of Facebook. In any case, I think it would be very helpful for us to come up with a realistic scenario, and use this scenario to help explain the workflow of our system in Figure 2. I believe this B2B scenario, where different companies need to share high-volumes of data efficiently and in a policy-compliant manner makes a lot of sense, and it could be a good way to highlight the challenges of scale, performance, and security. At the same time, we leave the real data owners -- the end-users -- out of the picture, because this will bring a whole new set of problems which I think we do not address at the moment in this paper. Even in the intro, we can motivate our system with the need for policy compliance in data sharing scenarios across organizations. This happens all the time, e.g., imagine Uber sharing location information with all other kinds of companies. The regulatory authority would then be responsible for guaranteeing the lawfulness of the entire thing, which brings the need for an accounting infrastructure.}

\nuno{If we focus on this scenario, we could try to motivate this paper by focusing on this concrete research question: \textit{How can we build a query processing / storage infrastructure that enables organizations to process high-volumes of shared security-sensitive data with strong GDPR compliance guarantees, high-performance, and hard protection against powerful adversaries?}. To answer this question, we present a system based on a computational storage architecture which we enhance with three new techniques/mechanisms. These are the mechanisms we can highlight as being the core contributions of our work, each of them solves a specific technical challenge:}

\nuno{(1) \textit{GDPR-aware policy specification language for query processing:} GDPR policies can be quite broad and involve various parties with different responsibilities. The challenge is to come up with a policy specification language that combines (a) simplicity in the specification (it must be simple to write and to interpret by different parties, (b) expressive enough to cover the most important GDPR anti-pattern use cases, and (c) efficient to evaluate. We address these challenges: our solution is described in 4.4 and 4.5.}

\nuno{(2) \textit{Policy-compliant query processing infrastructure}. Technical challenges to address: (a) need to have efficient mechanism to enforce per-query policies and generate proofs of compliance that may be requested by the regulatory authorities, (b) there is the problem of scale with many different machines in the data center and the distribution of query processing workflow, this needs to scale with number of queries and servers/storage devices, consume as little storage/bw resources as possible. The solution here is the attestation protocols implemented by the trusted monitor, the possibility to have many trusted monitor instances to allow for scaling the system, and I suggest we include a mechanism that can generate proofs of compliance, i.e., for each query, the host and the storage device generate a report that contain signatures of the hash of the query, hash of the policy, version number of the database, timestamp, id of the client that has submitted the query, attestation quotes of the servers and storage devices, and other necessary metadata. These reports can be sent to the monitor, which can be stored on the log for auditing purposes. This will allow the regulatory authorities or other parties to obtain proof of compliance and/or refute complains of non-compliance.}

\nuno{(3) \textit{Heterogeneous confidential-compute infrastructure}. Here I suggest we unify both the ``heterogeneous shielded execution framework'' and ``secure storage system''. This is because they both pertain to a common security infrastructure that aims to protect data in all stages: processing and storage, respectively. We can present the challenges we already have in the paper, and propose our current solution; but I'd present both these components as part of the same infrastructure.}
\fi 
\if0 %before David's update
The diagram shown in \autoref{fig:secndp-arch_overview} represents a high-level view of the \project{} architecture. It consists of the following components: \textit{client}, \textit{frontend}, \textit{backend}, and \textit{trusted monitor}. The client is a piece of software that provides an interface to end-users. It can be executed remotely or on the cloud infrastructure where the remaining components reside. The client provides a service for the submission of queries alongside with a user-defined security policy. The \project{} frontend, which runs on a dedicated cloud server, is responsible for handling the queries submitted by the clients. Upon receiving a query with an attached security policy, the \project{} frontend must first validate this request against the \project{} trusted monitor. The trusted monitor checks the security policies and coordinates their enforcement across the cluster. Based on the results returned by the trusted monitor, the \project{} frontend splits the query and dispatches it to a \project{} backend server where the data required to process the query is located. The backend servers are responsible for storing users' data on persistent storage and for executing the actual queries locally. When the execution of a query is completed, the \project{} backend sends back to the client both the query results and a proof of compliance to the security policy. To provide end-to-end security and policy compliance, \project{} relies on the following mechanisms:
\fi