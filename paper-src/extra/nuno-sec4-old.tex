\section{Design}
\label{sec:design}
We next present the detailed design of \project{} based on addressing the aforementioned three design challenges ($\S$\ref{subsect:design-challenges}).

\subsection{Heterogeneous Confidential Computing Framework}
\label{subsec:design-sef}

% \pramod{can we introduce the two aspects first?}
To address challenge \#1, we present the design of a heterogeneous confidential computing framework that allows to securely process SQL queries across the host and storage. Our Confidential computing framework consists of two aspects: (a) {\em shielded execution framework} for in-memory query execution ($\S$~\ref{subsec:shielded-exc}), and (b) {\em secure storage} to extend the trust from in-memory computing to secure the persistent data on untrusted storage medium ($\S$~\ref{subsec:design-storage}). % to occur on data whose confidentiality, integrity and freshness can be guaranteed

%However, since the framework only secures in-memory, volatile, code and data, we also describe the design of a secure storage framework that allows query processing to occur on data whose confidentiality, integrity and freshness can be guaranteed.

\subsubsection{Shielded execution framework}
\label{subsec:shielded-exc}

The framework consists of a distributed execution runtime that enables data processing queries to run across heterogeneous memory protection domains while preserving the confidentiality, integrity, and freshness of data and computations. The runtime is responsible for abstracting away the hardware-specific differences between domains and provides a unified interface to an application that intends to take advantage of the \csd
% NOTE: either CSA or CS architecture or computational storage architecture
for performance speedups. Our design choices are tailor-made to support seamless query execution across memory protection domains assisted by Intel SGX and ARM TrustZone technologies. Figure~\ref{fig:design-hetero-tee} presents the components of our framework. Next, we describe each of these components in turn. % and then explain how the split query execution workflow takes place.

\myparagraph{Host engine} In the host, which we assume to be an x86 server, the host engine runs inside a memory-protected domain implemented by a single SGX enclave. Together with two auxiliary components---the query engine and the query partitioner---the host engine is responsible for handling, partitioning, and dispatching the incoming query requests. The engine relies on an API, provided by the controller, that hides the fact that the engine is executing within an enclave and mediates interactions with the untrusted OS environment. Given that, these components execute within an enclave, untrusted parties cannot inspect their memory or tamper with critical operations (e.g., query partitioning). Thus, integrity and confidentiality of these operations, and of the data they operate on is guaranteed. %The host engine itself is agnostic to the fact that it lives inside an SGX enclave as all its interactions with the external environment are mediated by the controller.

\myparagraph{Trusted monitor} Similar to the host engine, the trusted monitor also runs in its own SGX enclave. This protection is necessary to guarantee the integrity of \project's attestation and policy enforcement mechanisms, and eventually, the trusted monitor can run on a separate machine by itself. In $\S$~\ref{subsec:design-trusted-monitor}, we describe it in more detail.

\myparagraph{Storage engine} In contrast to the host, the storage system is based on ARM architecture where the only available TEE-enabling technology is TrustZone (ARM v9 Realms~\cite{arm-cca} is not released yet). With a TrustZone-based TEE, a strawman approach for securing the storage engine would be to implement as a trusted application (TA) and run it inside the secure world. However, to enable split queries to access persistent data on the storage medium, the storage engine requires full-blown OS support with all the necessary device drivers and file systems. Typically, no such support is available in the secure world given that the trusted OS responsible for managing TAs is bare minimal.

To overcome this challenge, we employ a partitioned architecture spanning both the secure world and the normal world. The secure world only runs certain security-critical functions, including generation of remote attestation quotes, secure storage primitives, and securely bootstrapping the system. These functions are implemented as trusted applications (see Figure~\ref{fig:design-hetero-tee}). The normal world houses a supporting OS stack along with the storage engine's heavy-weight components namely the query engine and the secure storage system. To propagate trust from the secure world to the normal world, when the system bootstraps into the secure world, the trusted OS performs an integrity measurement (i.e., computes hashes) of the software components running in normal world and hands over the control execution to the normal world OS. Unless the hashes reflect \project's trusted software stack for the normal world the trusted monitor will consider the storage system unsafe and thus ineligible for handling query offloading requests.

As a result, the memory protection of the storage engine is assisted by two mechanisms: i) the storage system's TAs are protected by the secure world's trusted OS, and ii) the storage system's components that run in the normal world are supervised by a trusted OS stack. Analogously to the host counterpart, the query engine is agnostic to the fact that it runs inside a memory-protected environment assisted by TrustZone. The firmware on the storage system is also trusted to provide isolation between offloaded queries, and prevent them from reading and tampering with each other's code and data. Hence, we can guarantee that the confidentiality and integrity of offloaded queries and the data they process is protected.


\myparagraph{Split query execution} In the host, the controller receives a client request with an associated execution policy and passes it onto the request handler implemented by the host engine. The client's execution policy is checked (via interaction with the trusted monitor). If successful, control is passed over to the query partitioner, which splits the query into \textit{host query} and \textit{storage query}. The storage query is then offloaded to the storage system. Simultaneously, the host engine starts up the in-memory query engine to receive filtered data from the storage system once the offloaded storage query completes its execution. In the storage system, once the storage engine receives the offloaded query from the host, it launches the query engine. This component reads in data from the untrusted storage medium while relying on the secure storage framework to ensure that data being read is fresh and has not been tampered with. The secure storage trusted application is used, once, at the beginning of the execution of the storage-side query to verify the freshness of the data as described in $\S$~\ref{subsec:design-storage}. Upon receiving the results of storage query, the host query processes this data, and the host engine sends the final result to the client. 


%\pramod{The following can be covered in Section 3. It's already covered to a large extent.}
\if 0
\myparagraph{Split query execution} In the host, the controller receives a client request with an associated execution policy and passes it onto the request handler implemented by the host engine. The client's execution policy is checked (via interaction with the trusted monitor). If successful, control is passed over to the query partitioner, which splits the query into \textit{host query} and \textit{storage query}. The storage query is then offloaded to the storage storage system. Simultaneously, the host engine starts up the in-memory query engine to receive filtered data from the storage system once the offloaded storage query completes its execution. In the storage system, once the storage engine receives the offloaded query from the host, it launches the query engine. This component reads in data from the untrusted storage medium while relying on the secure storage framework to ensure that data being read is fresh and has not been tampered with. The secure storage trusted application is used, once, at the beginning of the execution of the storage-side query to verify the freshness of the data as described in $\S$~\ref{subsec:design-storage}. Upon receiving the results of storage query, the host query processes this data, and the host engine sends the final result to the client. Given that the protection domains on the host and on the storage system are connected via an untrusted channel, all communication between them must be secured. To this end, the client communicates with the host engine over a mutually authenticated and encrypted channel. To secure the communications between host engine and storage engine, the trusted monitor helps both endpoints to authenticate each other and exchange symmetric keys that will be used for establishing secure sessions. A one time randomly generated nonce is also included to ensure that all exchanges are fresh.
\fi

\subsubsection{Secure Storage System}
\label{subsec:design-storage}

To address the challenge of securing data stored in untrusted persistent storage, we present a secure storage framework. It guarantees the confidentiality, integrity, and freshness of data read from the untrusted storage medium, thereby preventing processing of queries with tampered or stale data. To satisfy these properties, our framework incorporates new mechanisms that implement: i) high-performing encryption/decryption of data blocks, ii) integrity checking and data rollback protection rooted on RPMB memory, and iii) key management functions to ensure secure data path between the storage engine and untrusted storage medium. 

Figure~\ref{fig:design-hetero-tee} shows the various components of the secure storage framework. The framework itself lives in the normal world, but runs in tandem with the secure storage TA hosted in the secure world. It offers an interface that allows the query engine to read or write units of data (fixed at \SI{4}{\kibi\byte}) stored on untrusted medium. Our framework ensures that data read or write operations can only be authorized (and thus executed) as long as the trusted monitor has i) vouched for the authenticity of the storage system setup, and ii) verified the compliance of this setup with the security policy originally provisioned by the client. \harsha{client or customer?}

The secure storage framework stores persistent state on both untrusted and trusted media. On an untrusted medium (e.g., SSD), it reserves a data region for storing the (encrypted) data units sequentially and a meta-data region that preserves a streamlined Merkle tree for integrity protection. It also keeps some critical secrets on RPMB-backed trusted medium. Next, we explain how it preserves all required security properties and handles the read/write operations.

\myparagraph{Confidentiality protection} The secure storage framework encrypts each data unit using a secret (symmetric) encryption key. For simplicity, \project uses a single key to encrypt all the data units, but other management schemes can be adopted (e.g., one key per unit). The secure storage TA generates this key during the system initialization and shares it with the secure storage framework after a verified boot. This security measure aims to prevent leakage of the encryption key by ensuring that it will be handed over exclusively to a trusted implementation of \project's storage system. To survive system reboots, the encryption key is stored in RPMB memory.

\myparagraph{Integrity protection} The secure storage framework generates a hash-based message authentication code (HMAC) for each data unit. It then recursively builds a Merkle tree also employing HMACs to create the internal nodes and root of the tree. This tree ensures that the data units cannot be silently displaced or suppressed by an adversary with physical access to the untrusted medium. The input key to generate the HMACs is deterministically derived from the data encryption key.

\myparagraph{Freshness protection}
To prevent rollback attacks and ensure that the Merkle tree itself is fresh, we need to only ensure that the root of the tree is fresh. To this end, we rely on the secure storage TA and on the RPMB region present in an eMMC. First, the storage TA needs to generate a new key derived from the secure storage key provided by the trusted OS. The secure storage key is generated from a unique, device-specific hardware key, which bounds the data to the CPU. The storage TA uses the new key to generate a HMAC of the Merkle tree root and writes down this HMAC to the RPMB. Freshness is preserved by verifying that the HMAC of the root of the Merkel tree matches the version stored on RPMB. Whenever the secure storage framework loads the Merkel tree from untrusted medium and needs to verify the freshness of the tree's root value, it sends a request to the secure storage TA to compare if this value is equal to the tree root value stored in the RPMB region. \project{} verifies the freshness of the Merkle tree only once at startup. This is because entry and exit to the secure world is a costly operation in light of having to check every data unit for freshness every time it is accessed.

\myparagraph{Read and write operations}
Consider the case when the query engine requests reading a single unit of data for processing. The secure storage framework reads the data unit from untrusted storage and loads it into memory. Once in memory, it then checks the integrity of the data unit by computing its HMAC and comparing it against the corresponding value in the Merkle tree. If they are equal, then the data in that unit has not been tampered with in any way. Granted that the framework had already verified the freshness of the Merkle tree (see above), we are also sure that the data unit is fresh and that it has not been reverted to a stale version. If any of these checks fails, the query processing is aborted, otherwise the framework decrypts the data unit content and returns the plaintext onto the query engine. For write operations, the framework generates a new HMAC of the data units to be written, updates the Merkle tree accordingly, encrypts the data units' new content, and stores the resulting ciphertext on untrusted medium. The framework also instructs the secure storage TA to update the RPMB memory based on the new value of the Merkel tree root.

\subsection{Policy compliance infrastructure}
\label{subsec:design-trusted-monitor}
\input{figures/design-attestation}

To address challenge \#2, we present the design of a policy compliance infrastructure that provides a unified interface to enforce client security policies across heterogeneous execution domains. We call this component the "Trusted Monitor". The monitor abstracts away the process of remote attestation of host and storage nodes by acting as their root of trust. Clients using \project{} are only required to directly trust the monitor, and submit queries and associated execution and data policies.

% Table~\ref{tab:example-policy} shows an example of a client policy. The policy contains three attributes: versions of the storage system software running in the normal and secure worlds, and the location of the storage system node. As an example, if a particular node does not conform to the policy, i.e., it is either located on a cluster outside the UK or the US, or runs normal or secure world software versions older than 2 or 3, respectively, then the \project{} service will not use it to process the client's request.

% \begin{table}
%     \centering
%     {\small
% \begin{tabular}{p{0.3\linewidth}p{0.6\linewidth}}
% \toprule
% {\bf  Policy} & {\bf Specification} \\
% \midrule
% P1 & FW-NW>=2 and FW-SW>=3 and (country="UK" or country="US") \\ 
% \bottomrule
% \end{tabular}
% }
% \caption{An example policy specified by the client over firmware measurements and locations of the storage server. \label{tab:example-policy}}
% \end{table}



The trusted monitor service runs inside an enclave, either on the host or on a dedicated server (see Figure~\ref{fig:design-hetero-tee}). To be able to enforce client policies, the first essential step is to obtain hard proof about the configuration of the host and storage system nodes. This proof must ascertain the authenticity and integrity of the software implementing the host engine and in the storage engine. Along with the trusted monitor software, these components constitute the trusted computing base of \project{} and therefore they cannot be tampered with. To obtain such a proof, the trusted monitor runs independent remote attestation protocols with host and storage nodes.
%Then, the second step to enforce client policies is to establish a client session made up of an end-to-end secure channel between attested components -- i.e., client-host and host-storage node -- through which \project{} serves and processes the client's query request. Next, we explain these steps in detail.

\paragraph{Attestation of the host:} Figure~\ref{fig:design-trusted-monitor}.a describes the steps during which the trusted monitor remotely attests the integrity and authenticity of the software running in the host engine enclave. After establishing a secure channel over TLS (step 1), the trusted monitor issues a quote request to the host (step 2), who replies with a quote response (step 3). Then, by checking the quote signature, the trusted monitor decides whether the configuration of the host is trustworthy. If so, it generates a public key pair where the public key is certified by the trusted monitor, and sends this information to the host over the secure channel (step 4). The public key certificate will be used by the host to prove to the client that the host has been remotely attested. If the quote verification fails, then the operation is aborted and the host is not authorized to serve \project client requests.

\paragraph{Attestation of the storage system:} The remote attestation of a storage system node involves the interaction between the trusted monitor and the attestation TA running in secure world (see Figure~\ref{fig:design-hetero-tee}). As mentioned in $\S$~\ref{subsec:design-sef}, we rely on a secure boot process to check the storage engine software.
%to ensure that the storage engine software has not been tampered with, we rely on the secure boot process operated by the secure world firmware. 
The root of trust for this process is a device-specific, unique key called the \textit{root of trust public key} (ROTPK), and the initial boot firmware is present in tamper proof ROM. This mechanism ensures that only integrity-protected firmware, signed by trusted parties, will run. The attestation TA leverages this mechanism during the remote attestation protocol. Figure~\ref{fig:design-trusted-monitor}.b describes the steps of this protocol.
The trusted monitor in step (1) requests the certificates from the storage node and challenges the node to prove its authenticity. In step (2) the TA obtains the measurement of the software running in normal world, and step (3) generates a response to the challenge by signing the challenge with a unique key, derived from the ROTPK. %device specific hardware key (i.e., the ROTPK).
In step (4) the TA sends the challenge response, the normal world firmware hash, and the certificate chain generated during secure boot of the storage node. The trusted monitor then verifies the response to the challenge to determine the authenticity of the storage system. The certificate chain is also verified, and on success, the storage node configuration is derived from the certificate chain. Both the configuration data and the certificate chain are used for policy enforcement as explained next. 

\paragraph{Client session:} To execute a query while complying with a user-defined security policy, the client first connects to and attests the trusted monitor service. It then submits the query and associated execution policy to the host. The host forwards the query to the monitor, which then checks which if the host and storage nodes comply with the execution policy. The monitor then sends the policy compliant query and the list of compliant storage nodes to a compliant host node, along with a session key that allows the host to connect securely to the storage node and process the query as explained in the sections above. If none of the storage nodes comply with the client's execution policy then the entire query may be processed on the host node itself. Once the client request has been completed, the monitor initiates a session cleanup protocol. This deletes any sensitive information including the temporary data created during the processing of the request.

\paragraph{Query partitioning:} Based on the results of the policy checks the host decides whether the query is processed across both the host and storage nodes, or only on the host node or not processed at all. For the first case, it needs to partition the query into portions that run on the host and storage nodes respectively. In our current system, we partition the queries based on operator rules only, without taking into other factors in the setup.

\paragraph{Policy interpreter:} The trusted monitor runs a policy interpreter which converts the client defined policy written in the \project{}'s policy language, described later, into a form that can be easily parsed and understood by the monitor. The interpreter uses the integrated list of predicates and of supported operations to parse and interpret the policy. The monitor then uses the data access policies, defined by the data owner, to authenticate the request from the client. If successful, the monitor uses the information obtained during attestation to create an execution environment to process queries, such that it is compliant with the environment defined by the client's execution policy.
% host over TLS and receives a certified public key proving that the host was attested by the trusted monitor. If so, the client submits the query along with the policy to the host. The host sends the policy to the trusted monitor who checks for storage nodes that match the policy conditions. 
%. The policy is then sent to the trusted monitor, which checks potential storage system candidates that match the policy conditions. %This is achieved by comparing the node configuration to the client defined execution policy. 
% As an example, if for policy P1 in \autoref{tab:example-policy} the storage node does not satisfy a FW-SW >= 3, then the query is not offloaded to the storage node and the entire query is run on the host itself. The host engine then receives the list of storage nodes that abide by the policy along with a session key that allows the host to connect securely to the storage node and process the query as explained in the sections above. %establish a secure channel with the storage system node. Once the channel is established the query is processed as explained in the sections above. 

% \harsha{Add stuff about the interpreter and language, similar to pesos. Also the API for different actors, similar to guardat. Abstract out trusted monitor ops and move TM into impl.}

\subsection{\project{} API and policy language}
\label{sec:policylanguage}

To address challenge \#3, \project{} exposes different APIs to all actors in the setup. We also present a declarative policy language that can be used to specify data access and execution policies concisely.

\subsubsection{\project{} API}

\project{} defines three kinds of actors, namely: data owners, data consumers and regulatory authorities. Each of these perform different kinds of tasks. To be more specific, data owners generate data and tie access and usage policies to that data. Data consumers process data owners' data in a manner that is allowed by the data owner. Finally, regulatory authorities are responsible for auditing investigating data breaches and violations of policies. We describe interfaces to establish sessions with \project{}, submit user data for storage, tie policies to user's data, update those policies at a future point in time and obtain information on how their data was used and shared. Additionally, data consumers have the ability to read and process data, whereas regulators need to be able to audit and investigate data breaches and policy violations by data controllers and consumers. Next we describe the interface exposed to every actor in the setup.

\myparagraph{Session interface}
All actors in the system interact with \project{} in a session. When an actor connects to \project{}, they present a TLS certificate to authenticate themselves. Once authenticated, a mutually encrypted channel is created to exchange data and commands between the actor and \project{}. The trusted monitor uses the public identity key of the connected actor to figure out if it has the right permissions to read and write data by executing queries. Moreover, the connecting actor can also \emph{attest} the trusted monitor to ensure that it runs the correct, untampered, software and hardware.

\myparagraph{Access interface}
As described later, \project{} supports three kinds of operations: read, write and exec. Actors use these operations to store their data on \project{}, tie access policies to the stored data, update policies associated with the stored data and also update stored data. Additionally, they can also run queries that process the stored data provided they have the permission to do so. Policies are created, optionally, during data insertion. They are updated later, using a \emph{updatePolicy} operation that takes a new policy and a second parameter that represents a \emph{strong} or \emph{eventual} enforcement of the new policy. Since data and associated metadata for policy compliance can be replicated and distributed across multiple storage nodes, the metadata to reflect the new policy must be updated everywhere. If a \emph{strong} update is preferred, then the trusted monitor blocks all requests to the data associated with that policy, until all metadata has been updated to reflect the restrictions imposed by the new policy. Else, if \emph{eventual} update is preferred, the trusted monitor does not block any requests to that data.

\myparagraph{Audit interface}
To be able to investigate data usage and policy violations, \project{} allows a data owner or an external party, who has been permitted by the data owner, to obtain information on the ways the data owner's data was shared, used and processed. Data owners enforce logging of data and allow an external party to access this log through an \emph{obtainUserLog} operation.

\subsubsection{Policy language}
% \harsha{spin gdpr challenges in context of ndp; add a time component; our work handles the "risk agnostic data processing"; }

\input{tab_language}
\project{}'s policy language allows a client to concisely specify the execution context associated with the execution of a query in a split manner, across the host and storage. By specifying the execution context the client indirectly enforces security policies, for example, by enforcing the firmware that is used to run the query in a split manner. Moreover, the data owner can also specify data access policies during data creation using the policy language, which are enforced by the trusted monitor, during an update or deletion of data at a later point in time. We describe a few use cases that can be supported by our language in section~\ref{sec:use-cases}.

Predicates that can be used to compose policies using \project{}'s policy language are shown in table~\ref{tab:secndp-language}. The table describes four kinds of policy attributes. \emph{sessionKeyIs} enables a client to derive policies to restrict access, by reading or writing, to data, only to certain users based on their identity key $k$. The second kind of predicates enable a client to run data processing operations on nodes, host or storage, only if they are located in a region or regions. The client uses the \emph{storageLocIs} predicate to enforce the offloading of queries only to storage nodes located in region $l$. If no nodes satisfy this property then, as described before, the entire query may be run on the host node itself. The client uses the \emph{hostLocIs} predicate to enforce the running of queries only on host nodes that are located in a specific region $l$. Similarly, the client uses the firmware predicates to enforce processing of queries on nodes that are running software greater than or equal to a certain version $v$. The final two predicates enable a client to specify how their data can be used by an external entity and record all operations that are performed by that entity.

A policy in \project{} is a combination of predicates described in table~\ref{tab:secndp-language}. A policy evaluates to true, if and only if all the predicates specified in the policy evaluate to true. In \project{} we have two kinds of policies: \emph{Data Access} and \emph{Data Execution} policies. Data execution policies are specified by the client when executing queries. They can be any combination of location and firmware predicates. Data access policies are created (or updated) by the client that creates the database and tables in that database. These policies are associated with permissions for reading or writing on the database or its tables. They are of the form \textit{perm~:condition}. The condition is a combination of predicates and evaluates to true only if all predicates evaluate to true. An example data access policy is shown below in which user A can read and user B can write to the database.
\[
\begin{array}{@{}l@{}}
read~:-~sessionKeyIs(K_{\tt A})\\
write~:-~sessionKeyIs(K_{\tt B})\\
exec~:-~fwVersionStorage(latest) \& fwVersionHost(latest)\\
\end{array}
\]
More complex policies, that can be used in the real world to adhere to GDPR rules are described in section~\ref{sec:use-cases}.